---
title: "Week 15 Activity"
output: pdf_document
---

```{r setup, include=FALSE}
library(knitr)
library(rjags)
library(runjags)
library(tidyverse)
library(arm)
set.seed(04262023)
knitr::opts_chunk$set(echo = TRUE)
```


For this activity we will use NBA free throw shooting data.

```{r, echo = F}
playoff.free.throws <- tibble(
  player = c('James','Curry','Irving','Durant','Wall','Leonard','Beal','Harden','Love','Horford','Aldridge','Green','Paul','Olynyk','Parker','Favors','Jordan','Oladipo'),
  position = c('F','G','G','F','G','G','G','G','F','F','F','F','G','F','G','F','F','G'),
  FTA = c(162,114,84,103,93,102,61,115,75,29,55,67,33,30,14,23,56,6),
  FTM = c(113,103,76,92,78,95,50,101,63,22,42,46,29,22,14,11,22,6)) %>% 
  arrange(position, player)
playoff.free.throws %>% kable(digits = 2)
```

#### JAGS Code for Hierarchical Model
```{r, echo = F, message = F}
# Data
guards <- playoff.free.throws %>% filter(position == 'G')
Nsubj <- nrow(guards)
dataList = list(z=guards$FTM, N=guards$FTA,Nsubj = Nsubj)
```

```{r}
# Model - see page 250 in text
modelString <- 'model {
  for ( s in 1:Nsubj ) {
    z[s] ~ dbin( theta[s], N[s] )
    theta[s] ~ dbeta( omega*(kappa-2)+1, (1-omega)*(kappa-2)+1)
  }
  omega ~ dbeta(2.55, .45) # 85%
  kappa <- kappaMinusTwo + 2
  kappaMinusTwo ~ dgamma(.01, .01)
}'
writeLines( modelString, con='HierModel.txt')


# RUN JAGS
jags.hier <- jags.model( file = "HierModel.txt", 
                         data = dataList, 
                         n.chains = 3, 
                         n.adapt = 50000)
update(jags.hier, 10000)

num.mcmc <- 10000
codaSamples <- coda.samples( jags.hier, 
                             variable.names = c('omega', 'kappa','theta'), 
                             n.iter = num.mcmc)
```

```{r, echo = F}
guards <- guards %>% mutate(FT.PCT  = FTM / FTA)
cbind(guards, 
      post.mean = colMeans((combine.mcmc(codaSamples))[,-c(1:2)]),
                           HPDinterval(combine.mcmc(codaSamples))[-c(1:2),]) %>% 
  kable(digits = 2)
```

The mean and HPD values for omega and kappa are

```{r}
HPDinterval(combine.mcmc(codaSamples))[1:2,]
colMeans((combine.mcmc(codaSamples))[,c(1:2)])

```



## Exercises

1. Specify independent models using a uniform prior for $\theta$ for the players Curry, Beal, and Oladipo. Write the the sampling model and priors for these models. Recall you can find the posterior here analytically without using MCMC.

\vfill

2. Specify independent models using an informative prior, of your choice, for $\theta$ for the players Curry, Beal, and Oladipo. Write the the sampling model and priors for these models. Recall you can find the posterior here analytically without using MCMC. Defend your prior choice.
\vfill


3. Compare the posterior HDI from these models with those found using the hierarchical models. Note the HPDinterval function can be applied directly to samples from a beta distribution as `HPDinterval(mcmc(data  = rbeta(n = 5000, shape1 = a.star, shape2 = b.star)))`


#### Uniform Priors
- Beal (50 / 61 = `r round(50/61, 2)`) 

- Curry (103/ 114 = `r round(103/114, 2)`) 

- Oladipo (6/ 6 = `r round(6/6, 2)`) 


#### Informative Priors
- Beal (50 / 61 = `r round(50/61, 2)`) 

- Curry (103/ 114 = `r round(103/114, 2)`)

- Oladipo (6/ 6 = `r round(6/6, 2)`) 
\vfill

4. Reflect on the differences/similarities in the credible intervals between the two different priors as well as the hierarchical model. If you were going to bet on the players shooting percentages for the next season, which would you prefer?


\vfill

5. Now fit a frequentist model to estimate $\theta$ for the players Curry, Beal, and Oladipo. Describe the sampling model you've assumed with your code (hint: `glm()` is one possible route). Discuss the differences in your intervals with what you've computed in part 3. If you had to choose one analysis: HM, Bayes with uniform priors, Bayes with informative priors, or the frequentist approach which would you choose and why? 
\vfill



\vfill
\vfill
\newpage

## Optional Exercise

Use a dataset containing baseball batting averages and fit a hierarchical model with the groups as the player positions. Your goal is to model batting averages of the players and assess the differences between the player positions in this dataset.
```{r}
BattingAverage <- read.csv('http://math.montana.edu/ahoegh/teaching/stat491/data/BattingAverage.csv')
head(BattingAverage)
```

Assume this is an analysis you have been asked to perform as part of a job interview. Write a 1-2 page summary of your analysis using R Markdown. This should include an introduction and conclusion.

```{r, eval=F}
# Data
z <- BattingAverage$Hits
N <- BattingAverage$AtBats
s <- BattingAverage$PlayerNumber
c <- BattingAverage$PriPosNumber
Nsubj = length(unique(s))
Ncat =  length(unique(c))

dataList = list(
    z = z ,
    N = N ,
    c = as.numeric(c) , # c in JAGS is numeric, in R is possibly factor
    Nsubj = Nsubj ,
    Ncat = Ncat
  )

# Model
modelString = "
  model {
    for ( sIdx in 1:Nsubj ) {
      z[sIdx] ~ dbin( theta[sIdx] , N[sIdx] )
      theta[sIdx] ~ dbeta( omega[c[sIdx]]*(kappa[c[sIdx]]-2)+1 , 
                           (1-omega[c[sIdx]])*(kappa[c[sIdx]]-2)+1 ) 
    }
    for ( cIdx in 1:Ncat ) {
      omega[cIdx] ~ dbeta( omegaO*(kappaO-2)+1 , 
                           (1-omegaO)*(kappaO-2)+1 )
      kappa[cIdx] <- kappaMinusTwo[cIdx] + 2
      kappaMinusTwo[cIdx] ~ dgamma( 0.01 , 0.01 ) # mean=1 , sd=10 (generic vague)
    }
    omegaO ~ dbeta( 1.0 , 1.0 ) 
    kappaO <- kappaMinusTwoO + 2
    kappaMinusTwoO ~ dgamma( 0.01 , 0.01 )  # mean=1 , sd=10 (generic vague)
  }
  " 
writeLines( modelString, con='HierModelComb.txt')

# Initialize
initsList = function() {
    thetaInit = rep(NA,Nsubj)
    for ( sIdx in 1:Nsubj ) { # for each subject
      resampledZ = rbinom(1, size=N[sIdx] , prob=z[sIdx]/N[sIdx] )
      thetaInit[sIdx] = resampledZ/N[sIdx]
    }
    thetaInit = 0.001+0.998*thetaInit # keep away from 0,1    
    kappaInit = 100 # lazy, start high and let burn-in find better value
    return( list( theta=thetaInit , 
                  omega=aggregate(thetaInit,by=list(c),FUN=mean)$x ,
                  omegaO=mean(thetaInit) ,
                  kappaMinusTwo=rep(kappaInit-2,Ncat) ,
                  kappaMinusTwoO=kappaInit-2 ) )
}

 # RUN THE CHAINS
  parameters = c( "theta","omega","kappa","omegaO","kappaO") 
  adaptSteps = 10000             # Number of steps to adapt the samplers
  burnInSteps = 10000            # Number of steps to burn-in the chains
  nChains = 2
  num.mcmc = 50000

# MCMC
jagsModel = jags.model( "HierModelComb.txt" , data=dataList , inits=initsList , 
                            n.chains=nChains , n.adapt=adaptSteps )
    # Burn-in:
    cat( "Burning in the MCMC chain...\n" )
    update( jagsModel , n.iter=burnInSteps )
    # The saved MCMC chain:
    cat( "Sampling final MCMC chain...\n" )
    codaSamples = coda.samples( jagsModel , variable.names=parameters , 
                                n.iter=num.mcmc)

HPDinterval(codaSamples)
```

